{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme events detection\n",
    "\n",
    "According to IEC standards there are 6 main classes of exteme events:\n",
    "\n",
    "    - Extreme wind speed model (EWM)\n",
    "    - Extreme operating gust (EOG)\n",
    "    - Extreme turbuelnce model (ETM)\n",
    "    - Extreme direction change (EDC)\n",
    "    - Extreme coherent gust wind direction change (ECD)\n",
    "    - Extreme wind shear (EWS)\n",
    "\n",
    "Each of these are to be quantified through the high resolution data, as they typically happen over a range of < 10s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fundamentals\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from calendar import monthrange, month_name\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "import imp\n",
    "import scipy.io as sio\n",
    "import pickle as pkl\n",
    "import csv\n",
    "# plotting libraries and setup\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', size=12)\n",
    "plt.rc('facecolor', )\n",
    "\n",
    "# met mast functions and utilities\n",
    "sys.path.append('../')\n",
    "import met_funcs as MET\n",
    "import vis as vis\n",
    "import utils as utils\n",
    "\n",
    "\n",
    "# # to read .mat files\n",
    "# import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time range\n",
    "years  = [ int(a) for a in np.arange(2012,2019,1) ] #\n",
    "months = [ int(a) for a in np.arange(1,12.1,1) ]\n",
    "days = [int(a) for a in np.arange(1,31.1,1)]\n",
    "\n",
    "# paths (must mount volume smb://nrel.gov/shared/wind/WindWeb/MetData/135mData/)\n",
    "towerID = 'M5'\n",
    "figPath = '../../figs/{}'.format(towerID)\n",
    "\n",
    "metDataPath = '/Volumes/135mData/{}Twr/20Hz/mat/'.format(towerID)\n",
    "# metDataPath = '/Users/nhamilto/Documents/Wake_Dynamics/SiteChar/data/M5/20Hz/'\n",
    "\n",
    "\n",
    "# with open('hi_res_data_channels.csv', 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     varnames = list(reader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 20Hz data for 2017/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n",
      "../met_funcs.py:610: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  theta_e = np.degrees(4*np.arctan(sigma_1/(vslice['WS'].iloc[0]*(1+0.1*params['D']/params['Lambda_1']))))\n"
     ]
    }
   ],
   "source": [
    "# years = [2017]\n",
    "# months = [2]\n",
    "# days=[4]\n",
    "probeheight=87\n",
    "            \n",
    "\n",
    "try:\n",
    "    savepath = '/Users/nhamilto/Documents/Wake_Dynamics/SiteChar/data/IEC_2'\n",
    "    os.makedirs(savepath)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        \n",
    "        # begin empty lists for events\n",
    "        Ve01events = pd.DataFrame()\n",
    "        Ve50events = pd.DataFrame()\n",
    "        EOGevents = pd.DataFrame()\n",
    "        ETMevents = pd.DataFrame()\n",
    "        EDCevents = pd.DataFrame()\n",
    "        ECDevents = pd.DataFrame()\n",
    "        EWSevents = pd.DataFrame()\n",
    "        \n",
    "        print('reading 20Hz data for {}/{}'.format(year,month))\n",
    "\n",
    "        for day in days:\n",
    "            datapath = os.path.join(metDataPath,str(year),str(month).zfill(2),str(day).zfill(2))\n",
    "\n",
    "            # establish existence of directory\n",
    "            try:\n",
    "                fPaths = os.listdir(datapath)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            if len(fPaths) is 0:\n",
    "                continue\n",
    "                \n",
    "            for filenum, file in enumerate(fPaths):\n",
    "                \n",
    "                # load data\n",
    "                try:\n",
    "                    data = sio.loadmat(os.path.join(datapath,file))#, variable_names=varnames)\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "                # if data is not complete, move on. No need to fight here.\n",
    "                ndat = 10*60*20 # minutes*seconds/minute*samples/second\n",
    "                if len(data['Sonic_CupEqHorizSpeed_100m'][0][0][0].flatten()) != 12000:\n",
    "                    continue\n",
    "                    \n",
    "                # make a vector of datetimes for the data\n",
    "#                 timerange = MET.make_datetime_vector(file)\n",
    "                timerange = utils.matlab_datenum_to_python_datetime(data['time_UTC'][0][0][0].flatten())\n",
    "    \n",
    "                # make a dataframe for the instrument at probeheight\n",
    "                sonicdat = MET.make_dataframe_for_height(data, timerange, probeheight=probeheight)\n",
    "                temp = sonicdat['WS'].dropna()\n",
    "                if len(temp)<1000:\n",
    "                    continue\n",
    "                    \n",
    "                # extract variables needed for classificiation of IEC events\n",
    "                params = MET.setup_IEC_params(sonicdat, probeheight=100)\n",
    "                \n",
    "                # look for extreme wind speed model events\n",
    "                Ve01eventfound, Ve50eventfound = MET.find_EWM_events(sonicdat, params)\n",
    "                Ve01events = pd.concat([Ve01events,Ve01eventfound])\n",
    "                Ve50events = pd.concat([Ve50events,Ve50eventfound])\n",
    "   \n",
    "                # look for extreme operating gust events\n",
    "                EOGeventfound = MET.find_EOG_events(sonicdat, params)\n",
    "                EOGevents = pd.concat([EOGevents,EOGeventfound])\n",
    "\n",
    "                # look for extreme turbulence model events\n",
    "                ETMeventfound = MET.find_ETM_events(sonicdat, params)\n",
    "                ETMevents = pd.concat([ETMevents,ETMeventfound])\n",
    "\n",
    "                # look for extreme direction change events\n",
    "                EDCeventfound = MET.find_EDC_events(sonicdat, params)\n",
    "                EDCevents = pd.concat([EDCevents,EDCeventfound])\n",
    "\n",
    "                # look Extreme coherent gust with direction change events\n",
    "                ECDeventfound = MET.find_ECD_events(sonicdat, params)\n",
    "                ECDevents = pd.concat([ECDevents,ECDeventfound])\n",
    "                \n",
    "#                 # look Extreme wind shear events\n",
    "#                 EWSeventfound = MET.find_EWS_events(sonicdat, params)\n",
    "#                 EWSevents = pd.concat([EWSevents,EWSeventfound])\n",
    "                \n",
    "        # save the data for each month        \n",
    "        eventlist = {'EWS_Ve01': Ve01events, \n",
    "                     'EWS_Ve50': Ve50events, \n",
    "                     'EOG': EOGevents, \n",
    "                     'ETM': ETMevents, \n",
    "                     'EDC': EDCevents, \n",
    "                     'ECD': ECDevents, \n",
    "                     'EWS': EWSevents}  \n",
    "                \n",
    "        filename = 'IEC_events_{}_{}.pkl'.format(year,month)\n",
    "        savefile = os.path.join(savepath,filename)\n",
    "        with open(savefile, 'wb') as f:\n",
    "            pkl.dump(eventlist, f, pkl.HIGHEST_PROTOCOL)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "149\n",
      "0\n",
      "56\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# demo load data\n",
    "loadfile = savefile\n",
    "# loadfile = '/Users/nhamilto/Documents/Wake_Dynamics/SiteChar/data/IEC/IEC_events_2015_1.pkl'\n",
    "with open(loadfile, 'rb') as f:\n",
    "    test= pkl.load(f)\n",
    "for key in test:\n",
    "    print(len(test[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
